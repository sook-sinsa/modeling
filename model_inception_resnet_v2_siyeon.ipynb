{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5g1Y9NTVTmcF"
   },
   "source": [
    "Required Modules import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IKiIs3-QfjKp",
    "outputId": "601c92e1-0df6-44a2-b212-2bfb1680e9a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.4.0\n",
      "1.19.4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "\n",
    "\n",
    "print(tf.__version__)\n",
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3YRPUs6LTriy"
   },
   "source": [
    "Loading Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lJELmcDyfoJ9",
    "outputId": "0bac4044-4ebd-46e3-d670-295371a7078d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "labelNames = ['cardigan_1_5',\n",
    "              'coat_1_10','coat_1_11','coat_1_12',\n",
    "              'collar_0_3','collar_0_4',\n",
    "              'dress_2_0','dress_2_1','dress_2_2',\n",
    "              'hood_0_6',\n",
    "              'jacket_1_1','jacket_1_2','jacket_1_3','jacket_1_4','jacket_1_6','jacket_1_7','jacket_1_8','jacket_1_9','jacket_1_17',\n",
    "              'jsuit_2_3',\n",
    "              'lpadding_1_13',\n",
    "              'lpants_3_0','lpants_3_1','lpants_3_2','lpants_3_3','lpants_3_5','lpants_3_6',\n",
    "              'lsleeve_0_1','lsleeve_0_5','lsleeve_0_7','lsleeve_0_8','lsleeve_1_0','lsleeve_1_18',\n",
    "              'nsleeve_0_2',\n",
    "              'skirt_4_0','skirt_4_1','skirt_4_2',\n",
    "              'spadding_1_14',\n",
    "              'spants_3_4',\n",
    "              'ssleeve_0_0',\n",
    "              'vest_1_15','vest_1_16'\n",
    "             ]\n",
    "print(len(labelNames))\n",
    "classDic = {0:2,\n",
    "            1:2, 2:2, 3:2,\n",
    "            4:2, 5:1,\n",
    "            6:5, 7:5, 8:5,\n",
    "            9:2,\n",
    "            10:2, 11:2, 12:2, 13:2, 14:2, 15:2, 16:2, 17:2, 18:2, \n",
    "            19:5,\n",
    "            20:2,\n",
    "            21:3, 22:3, 23:3, 24:3, 25:3, 26:3, \n",
    "            27:2, 28:2, 29:2, 30:2, 31:2, 32:2, \n",
    "            33:0,\n",
    "            34:4, 35:4, 36:4,\n",
    "            37:2,\n",
    "            38:3,\n",
    "            39:1,\n",
    "            40:0, 41:0\n",
    "           }\n",
    "print(len(classDic))\n",
    "classNames = ['nsleeve', 'ssleeve', 'lsleeve', 'pants', 'skirt', 'dress']\n",
    "\n",
    "dir = \"/Users/siyeon/Desktop/dataproject/data/collected/image\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JBFM3E90Tzg-"
   },
   "source": [
    "Create numpy data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0bkyjQ0iTboy"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "fileNames = []\n",
    "\n",
    "for idx, cat in enumerate(labelNames):\n",
    "\n",
    "    label = [0 for i in range(len(classNames))]\n",
    "    label[classDic[idx]] = 1\n",
    "\n",
    "    imgDir = dir + \"/\" + cat\n",
    "    files = glob.glob(imgDir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    \n",
    "    i = 0\n",
    "    lst = []\n",
    "    for i in range(len(files)) :\n",
    "        lst.append(i)\n",
    "    lst = pd.DataFrame(lst, columns = ['idx'])\n",
    "\n",
    "    trainSet = lst.apply(sampling, per=0.95)\n",
    "    trainSet = trainSet.sort_index()\n",
    "\n",
    "    testSet = lst.drop(lst.index[trainSet.index])\n",
    "    testSet = testSet.sort_index()\n",
    "\n",
    "    trainSet = trainSet['idx'].values.tolist()\n",
    "    testSet = testSet['idx'].values.tolist()\n",
    "    \n",
    "    for f in range(len(trainSet)):\n",
    "        img = Image.open(files[trainSet[f]])\n",
    "        img = img.convert(\"RGB\")\n",
    "        data = np.asarray(img)\n",
    "        \n",
    "        if f == 0:\n",
    "            print(label)\n",
    "            \n",
    "        x_train.append(data)\n",
    "        y_train.append(label)\n",
    "    \n",
    "    for f in range(len(testSet)):\n",
    "        img = Image.open(files[testSet[f]])\n",
    "        img = img.convert(\"RGB\")\n",
    "        data = np.asarray(img)\n",
    "        \n",
    "        if f == 0:\n",
    "            print(label)\n",
    "            \n",
    "        x_test.append(data)\n",
    "        y_test.append(label)\n",
    "        fileNames.append(files[testSet[f]])\n",
    "\n",
    "x_train = np.array(x_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "print(\"ok\", len(x_train), len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8LGJVIFhfvA6",
    "outputId": "e3627c56-aba0-4195-db80-277e95462ad4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16599, 125, 125, 3)\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "import tensorflow as tf\n",
    "config = tf.config.experimental\n",
    "\n",
    "imageLoad = np.load(\"/content/drive/MyDrive/Colab Notebooks/imageDataRaw.npz\")\n",
    "x_train = imageLoad['x_train']\n",
    "y_train = imageLoad['y_train']\n",
    "x_test = imageLoad['x_test']\n",
    "y_test = imageLoad['y_test']\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vvwZKvuCfwrf"
   },
   "outputs": [],
   "source": [
    "x_train = x_train.astype(float) / 255\n",
    "x_test = x_test.astype(float) / 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "496c8tBTUpr3"
   },
   "source": [
    "Modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fetNZV4kf0Nr"
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_resnet_v2 import InceptionResNetV2, preprocess_input\n",
    "\n",
    "base_model = InceptionResNetV2(include_top=False, pooling='avg')\n",
    "outputs = Dense(len(classNames), activation='softmax')(base_model.output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywze-YDXf1_I",
    "outputId": "fff74a02-4056-48c1-b160-eedff0bee636"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of layers in the base model:  781\n"
     ]
    }
   ],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "print(\"Number of layers in the base model: \", len(base_model.layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59B3SFk0f3lK"
   },
   "outputs": [],
   "source": [
    "model = Model(base_model.inputs, outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model_dir = './model'\n",
    "    \n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=6)\n",
    "checkpointer = ModelCheckpoint(filepath='/content/drive/Shareddrives/TimmyRoom/check',\n",
    "                              verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XixXHLJrf5Bl"
   },
   "outputs": [],
   "source": [
    "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size = 0.1)\n",
    "print(x_train.shape)\n",
    "print(x_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QEOD9KUqUsIn"
   },
   "source": [
    "Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t3kpidAcf6xS"
   },
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=32,steps_per_epoch=x_train.shape[0]//32,\n",
    "                    epochs = 100, verbose=2, callbacks=[checkpointer, early_stopping],\n",
    "                    validation_data=(x_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3W9v2MVhf9LJ"
   },
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model.save('/content/drive/MyDrive/Colab Notebooks/aug_all.weights.best.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o2NBAQOAf-pE"
   },
   "outputs": [],
   "source": [
    "model.load_weights('/content/drive/MyDrive/Colab Notebooks/aug_all.weights.best.hdf5')\n",
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "print('\\n','Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AB3_zLk0gAUt"
   },
   "outputs": [],
   "source": [
    "y_vloss = history.history['val_loss']\n",
    "y_loss = history.history['loss']\n",
    "\n",
    "x_len = np.arange(len(y_loss))\n",
    "\n",
    "plt.plot(x_len, y_vloss, marker='.', c='red', label='val_set_loss')\n",
    "plt.plot(x_len, y_loss, marker='.', c='blue', label='train_set_oss')\n",
    "plt.legend()\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "allData.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
